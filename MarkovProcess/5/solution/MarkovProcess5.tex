%!Mode:: "TeX:UTF-8"
%!TEX TS-program = xelatex
\documentclass{ctexart}
\newif\ifpreface
%\prefacetrue
\input{../../../global/all}
\begin{document}
\large
\iffalse
  \setlength{\baselineskip}{1.2em}
  \ifpreface
    \input{../../../global/preface}
  \else
    \maketitle
  \fi
\fi
\newgeometry{left=2cm,right=2cm,top=2cm,bottom=2cm}
%from_here_to_type
\begin{problem}\label{pro:1}
  Assume \((N_t:t \geq 0)\) is Possion process with parameter \(\alpha\), and \(\{\xi_n:n \in  \mathbb{N}^+\}\) is a sequence of i.i.d random variable.
  More over, assume \((N_t:t \geq 0) \perp \{\xi_n:n \in \mathbb{N}^+\}\).
  Let \(X_t=\sum_{k=1}^{N_t} \xi_k\).
  Let \(r>0\), prove that:
  \begin{enumerate}
    \item \((N_{t+r}-N_r:t \geq 0)\) is Possion process.
    \item \label{it:1.2}\(\{\xi_{N_r+n}:n \in \mathbb{N}^+\}\) is also i.i.d sequence with the same distribution of \(\{\xi_n:n \in \mathbb{N}^+\}\).
    \item \((N_{t + r}-N_r:t \geq 0)\perp (\xi_{N_r + k}:k \in \mathbb{N}^+)\).
    \item For \(0=t_0<t_1<\cdots<t_n\), we have \((X_{t_1},X_{t_{k+1}}-X_{t_k}:k=1,2,\cdots,n-1)\) are independent.
  \end{enumerate}
\end{problem}
\begin{solution}
  \begin{enumerate}
    \item
      Let \(\mathcal{F}_t:=\sigma(N_s:0 \leq s \leq t)\) and \(\mathcal{G}_t:=\sigma(N_{r+s}-N_r:0 \leq s \leq t)\).
      For \(0 \leq s \leq t\), we have \(N_{t+r}-N_r -(N_{s+r}-N_r)=N_{t+r}-N_{s+r} \sim Possion(\alpha(t-s))\).
      And easily to know \(N_{r + s}-N_r \in \mathcal{F}_{r+s}\), so \(\mathcal{G}_t \subset \mathcal{F}_{t+r},\forall t \geq 0\).
      Since \((N_t:t \geq 0)\) is Possion process, easily \(\mathcal{F}_{s+r} \perp N_{t+r}-N_{s+r}\).
      Since \(\mathcal{G}_{t}\subset \mathcal{F}_{t +r}\), we obtain \(\mathcal{G}_t \perp N_{t + r}-N_{s + r}=N_{t+r}-N_r -(N_{s+r}-N_r)\).
      Easily since \(N_t\) is right-continuous we get \(N_{t + r}-N_r\) is right-continuous.
      For the same reason, we know \(\forall s \in [0,\infty),\lim_{t \to s-}N_{t + r}-N_{r}\) exists.
      So \((N_{t+r}:t \geq 0)\) is Possion process.
    \item
      Only need to prove that for \(m \in \mathbb{N}^+\), the distribution of \((\xi_{N_r+k}:1 \leq k \leq m)\) is same as that of \((\xi_k:1 \leq k \leq m)\).
      For \(A_1,A_2,\cdots,A_m \in \mathcal{B}\), we have:
      \begin{equation}\label{equ:1}
        \begin{aligned}
                                                  & \mathbb{P}(\xi_{N_r+k}\in A_k,1 \leq k \leq m)                                       \\
          =                                       & \sum_{t=0}^{\infty} \mathbb{P}(\xi_{N_r + k} \in A_k,1 \leq k \leq m,N_r=t)          \\
          =                                       & \sum_{t=0}^{\infty} \mathbb{P}(\xi_{t + k} \in A_k,1 \leq k \leq m,N_r=t)            \\
          (N_r \perp (\xi_n:n \in \mathbb{N}^+))= & \sum_{t=0}^{\infty} \mathbb{P}(\xi_{t + k} \in A_k,1 \leq k \leq m)\mathbb{P}(N_r=t) \\
          =                                       & \sum_{t=0}^{\infty} \prod_{k=1}^{m} \mathbb{P}(\xi_{k+t} \in A_k)\mathbb{P}(N_r=t)   \\
          =                                       & \sum_{t=0}^{\infty} \prod_{k=1}^{m} \mu(A_k)\mathbb{P}(N_r=t)                        \\
          =                                       & \prod_{k=1}^{m} \mu(A_k)                                                             \\
        \end{aligned}
      \end{equation}
      where \(\mu\) is the distribution of \(\xi_1\).
      So we get for \(m \in \mathbb{N}^+\), the distribution of \((\xi_{N_r+k}:1 \leq k \leq m)\) is same as that of \((\xi_k:1 \leq k \leq m)\).
    \item
      We know that \(\forall t \in \mathbb{N}^+,\xi_{N_r + t} \in \sigma(N_r,\xi_k:k \in \mathbb{N}^+)\).
      So \(\sigma(\xi_{N_r + k}:k \in \mathbb{N}^+) \subset \sigma(N_r,\xi_k:k \in \mathbb{N}^+)\).
      Since \((N_t:t \geq 0)\) is Possion process, we get that \(N_{t + r}-N_r \perp N_r,\forall t \geq 0\).
      So \(\sigma(N_{t + r}-N_r:t \geq 0)\perp N_r\).
      Easily \(\sigma(N_{t + r}-N_r:t \geq 0)\perp \sigma(\xi_k:k \in \mathbb{N}^+)\), so finally we get that
      \(\sigma(N_{t + r}-N_r:t \geq 0)\perp \sigma(N_r,\xi_k:k \in \mathbb{N}^+)\supset \sigma(\xi_{N_r+k}:k \in \mathbb{N}^+)\).
    \item \(\forall 0 = t_0<t_1<\cdots<t_n\), then \(X_{t_1}=\sum_{i =1}^{N_{t_1}}\xi_i,X_{t_k}-X_{t_{k-1}}=\sum_{i=1}^{N_{t_k}-N_{t_{k-1}}}\xi_{N_{t_{k-1}} + i}\xi_i,k=2,\cdots,n\),
      then \(\forall\{A_k \in \mathscr{E}:k=1,\cdots,n\}\),
      \begin{equation}
        \begin{aligned}
            & \mathbb{P}(\bigcap_{k =1}^n \sum_{i=1}^{N_{t_k}-N_{t_{k-1}}}\xi_{i + N_{t_{k-1}}} \in A_k)                                                                                              \\
          = & \mathbb{P}(\bigcup_{0 \leq u_1\leq \cdots\leq u_n}\{\sum_{i=u_{k-1}+1}^{u_k}\xi_{i} \in A_k,N_{t_k}=u_k,k=1,\cdots,n\})                                                                 \\
          = & \sum_{0 \leq u_1\leq \cdots\leq u_n}\mathbb{P}(\sum_{i=u_{k-1} + 1}^{u_k}\xi_i  \in A_k, k=1,\cdots,n| N_{t_k}=u_k,k=1,\cdots,n\})\mathbb{P}(N_{t_{k}}=u_k,k=1,\cdots,n)                \\
          = & \sum_{0 \leq u_1\leq \cdots\leq u_n}\mathbb{P}(\sum_{i=u_{k-1} + 1}^{u_k}\xi_i  \in A_k, k=1,\cdots,n\})\mathbb{P}(N_{t_{k}}=u_k,k=1,\cdots,n)                                          \\
          = & \sum_{0 \leq u_1\leq \cdots\leq u_n}\prod_{k=1}^{n} \mathbb{P}(\sum_{i=u_{k-1} + 1}^{u_k}\xi_i  \in A_k)\prod_{j=1}^{n} \mathbb{P}(N_{t_{j}}=u_j)                                       \\
          = & \sum_{0 \leq u_1\leq \cdots\leq u_n}\prod_{k=1}^{n} \mathbb{P}(\sum_{i= 1}^{u_k-u_{k-1}}\xi_{u_{k-1}+ i}  \in A_k)\prod_{j=1}^{n} \mathbb{P}(N_{t_{j}}-N_{t_{j-1}}=u_j-u_{j-1})         \\
          = & \sum_{0 \leq u_1\leq \cdots\leq u_n}\prod_{k=1}^{n} \mathbb{P}(\sum_{i= 1}^{u_k-u_{k-1}}\xi_{u_{k-1}+ i}  \in A_k)\mathbb{P}(N_{t_{k}}-N_{t_{k-1}}=u_k-u_{k-1})                         \\
          = & \sum_{u_1-u_{0} \in \mathbb{N}}\cdots \sum_{u_n-u_{n-1} \in \mathbb{N}}\prod_{k=1}^{n} \mathbb{P}(\sum_{i= 1}^{u_k-u_{k-1}}\xi_{u_{k-1}+ i}  \in A_k,N_{t_{k}}-N_{t_{k-1}}=u_k-u_{k-1}) \\
          = & \prod_{k=1}^{n} \sum_{u_k-u_{k-1} \in \mathbb{N}}\mathbb{P}(\sum_{i= 1}^{u_k-u_{k-1}}\xi_{u_{k-1}+ i}  \in A_k,N_{t_{k}}-N_{t_{k-1}}=u_k-u_{k-1})                                       \\
          = & \prod_{k=1}^n\mathbb{P}(\sum_{i=1}^{N_{t_k}-N_{t_{k-1}}}\xi_{i + N_{t_{k-1}}}  \in A_k)
        \end{aligned}
      \end{equation}
  \end{enumerate}
\end{solution}
\begin{problem}\label{pro:2}
  Assume that \(X\) is Possion random measure on \((E,\mathcal{E})\) with intensity \(\mu\), which is a \(\sigma\)-finite measure.
  Assume \(f:E \to \mathbb{R}\) is measurable and non-negative, prove that:
  \[
    \mathbb{E}(\mathrm{e}^{-X(f)})=\exp \left\{-\int_{E}(1-\mathrm{e}^{-f(x)}) \mu(\d x)\right\}
  \]
\end{problem}
\begin{solution}
  Let \(\mathcal{L}:=\{g \in \mathcal{M}(E,[0,\infty)): \mathbb{E}(\mathrm{e}^{-X(f)})=\exp\left(-\int_{E}(1-\mathrm{e}^{-f(x)}) \mu(\d x)\right) \}\).
  First we prove that if \(g\) is simple measurable function from \(E\) to \([0,\infty)\), then \(g \in \mathcal{L}\).
  Assume \(g(x)=\sum_{k=1}^{n} a_k\mathbbm{1}_{A_k}(x)\), where \(A_k \in \mathcal{E},a_k >0,A_i \cap A_j = \emptyset\).
  Then \(\mathbb{E}(\exp(-X(g)))=\mathbb{E}(\prod_{k=1}^{n} \exp(-a_k X(A_k)))=\prod_{k=1}^{n} \mathbb{E}(\exp(-a_k X(A_k)))\), since \(X(A_k):k=1,\cdots,n\) are independent.
  Easily to know
  \[
    \mathbb{E}(\exp(-a_k X(A_k)))=\sum_{i=0}^{\infty} \mathbb{P}(X(A_k)=i) \exp(-a_k i)=\sum_{i=0}^{\infty} \frac{\exp(-\mu(A_k))\mu(A_k)^i}{i!} \exp(-a_k i)
  \]
  Noting that
  \[
    \exp(-\int_{E}(1-\exp(-a_k\mathbbm{1}_{A_k}(x))) \mu(\d x))=\exp(\exp(-a_k) \mu(A_k) - \mu(A_k))=\exp(-\mu(A_k))\sum_{i=0}^{\infty} \frac{(\exp(-a_k) \mu(A_k))^i}{i!}
  \]
  we get \(\mathbb{E}(\exp(-a_k X(A_k)))=\exp(-\int_{E}(1-\exp(-a_k\mathbbm{1}_{A_k}(x))) \mu(\d x))\).
  Noting \(\int_{E}(1-\exp(-g(x))) \mu(\d x)=\sum_{k=1}^{n}\int_{E}(1-\exp(-a_k\mathbbm{1}_{A_k}(x))) \mu(\d x)\),
  we get \(\mathbb{E}(\exp(-X(g)))=\exp\left(-\int_{E}(1-\exp(-g(x))) \mu(\d x)\right)\).

  Now for non-negative function \(f\), consider \(f_n\) satisfy that \(\forall n,f_n\) is simple, and \(f_n \nearrow f \) and \(f_n \geq 0\).
  Then easily to know \(\mathbb{E}(\exp(-X(f)))=\lim_{n \to \infty}\mathbb{E}(\exp(-X(f_n)))=\lim_{n \to \infty}\exp(-\int_{E}(1-\exp(-f_n(x))) \mu(\d x))=\exp(-\int_{E}(1-\exp(-f(x))) \mu(\d x))\).
\end{solution}
\begin{problem}\label{pro:3}
  Assume \(\mu\) is finite measure on \((E,\mathcal{E})\), and \(X\) is Possion random measure with intensity \(\mu\).
  Assume \(\phi:(E,\mathcal{E}) \to (F,\mathcal{F})\) is measurable, prove that
  \(X \circ \phi^{-1}\) is Possion random measure with intensity \(\mu \circ \phi^{-1}\).
\end{problem}
\begin{solution}
  Assume \(B_k \in \mathcal{F},\forall k \in \mathbb{N}\) and \(\forall i \neq j,B_i \cap B_j = \emptyset\).
  Then \(X \circ \phi^{-1} (\bigcup_{k \in \mathbb{N}}B_k)=X(\bigcup_{k \in \mathbb{N}}\phi^{-1}(B_k))=\sum_{k \in \mathbb{N}}X(\phi^{-1}(B_k))\).
  Since \(X\) is possion random measure with intensity \(\mu\), and for \(B_1,\cdots,B_n \in \mathcal{F}\) and \(B_i \cap B_j=\emptyset\), we have \(\phi^{-1}(B_k)\) are disjoint set in \((E,\mathcal{E})\), so
  \(\mathbb{E}(\exp(\mathrm{i}\sum_{k=1}^{n} \alpha_k X \circ \phi^{-1}(B_k)))=\exp(\sum_{k=1}^{n} (\exp(\mathrm{i}\alpha_k)-1)\mu \circ \phi^{-1}(B_k))\).
  So \(X \circ \phi^{-1}\) is Possion random measure on \((F,\mathcal{F})\) with intensity \(\mu \circ \phi^{-1}\).
\end{solution}
\begin{problem}\label{pro:4}
  Assume \(\alpha \geq 0\), and \(\mu\) is probability measure on \(\mathbb{R}\) with \(\mu(\{0\})=0\).
  Let \(N(\d s,\d z,\d u)\) is Possion random measure on \(\mathbb{R}^+ \times \mathbb{R} \times \mathbb{R}^+\) with intensity \(\d s \mu (\d z) \d u\).
  Let \(Y_t=Y_0+\int_{0}^{t} \int_{\mathbb{R}}\int_{0}^\alpha z N(\d s,\d z, \d u)\), where \(Y_0 \perp N\).
  Prove that \((Y_t:t \geq 0)\) is compound Possion process with rate \(\alpha\) and jumping distribution \(\mu\).
\end{problem}
\begin{solution}
  We know that \(\forall t \geq 0,\forall r:0 \leq r \leq t,Y_r \in \sigma(N(B):B \subset [0,r]\times \mathbb{R} \times [0,\alpha])\).
  And \(\forall w \geq t\), \(Y_w-Y_t \in \sigma(N(B):B \subset (t,w] \times \mathbb{R} \times [0,\alpha])\).
  Easily \((t,w] \cap [0,r]=\emptyset\), so we get \(Y_w-Y_t \perp (Y_r:0 \leq r \leq t)\).
  Now we only need to check the distribution of \(Y_w - Y_t\).
  Since \(\d s \mu(\d z) \d u\) has the same distribution with \(\d(s-t) \mu(\d z)\d u\), we get that \(Y_w - Y_t \overset{d}{=} Y_{w-t}-Y_0\).
  So we only need to check the distribution of \(Y_t-Y_0\).

  Since the distribution of \(Y_t-Y_0\) is determined by the distribution of \(N\) on the set \([0,t]\times \mathbb{R} \times [0,\alpha]\), so we can assume \(N\) is constructed as 1.5.5,
  because this will not change the distribution of \(N\) on \([0,t] \times \mathbb{R} \times [0,\alpha]\).
  Let \(\eta \sim Possion(\alpha t)\) and \(\xi_1,\cdots\) are i.i.d r.v. range in \([0,t] \times \mathbb{R} \times [0,\alpha]\) with distribution \(\d s \mu(\d z)\d u\), and \(\eta \perp (\xi_n:n \in \mathbb{N}'+)\).
  Assume for \(B \subset [0,t]\times \mathbb{R} \times [0,\alpha]\) we have \(N(B)=\sum_{j=1}^{\eta} \delta_{\xi_j}(B)\).
  Then we get \(Y_t-Y_0=\sum_{j=1}^{\eta} \xi_j(2)\), where \(\xi_j(2)\) is the second ordinate of \(\xi_j\).
  Easily \(\xi_j(2)\sim \mu,\eta \sim Possion(\alpha t)\), so finally we get \((Y_t:t \geq 0)\) is the compound distribution with rate \(\alpha\) and jumping distribution \(\mu\).
\end{solution}
\begin{problem}\label{pro:5}
  Assume \(X\) is Possion random measure on \((E,\mathcal{E})\) with intensity \(\mu\), a finite measure.
  Assume \(f,g\) are non-negative measure function on \(E\).
  Prove that:
  \begin{enumerate}
    \item \(\mathbb{E}(X(f)\mathrm{e}^{-X(g)})=\mu(f \mathrm{e}^{-g})\mathbb{E}(\mathrm{e}^{-X(g)})\).
    \item \(\mathbb{E}(X(f)^2 \mathrm{e}^{-X(g)})=(\mu(f^2 \mathrm{e}^{-g}+\mu(f \mathrm{e}^{-g})'2))\mathbb{E}(\mathrm{e}^{-X(g)})\).
  \end{enumerate}
\end{problem}
\begin{solution}
  \begin{enumerate}
    \item
      Let \(h(\theta):=\mathbb{E}(\mathrm{e}^{-X(\theta f + g)})=\exp\left(-\int_{E}(1-\mathrm{e}^{-\theta f(x) - g(x)} \mu(\d x))\right)\).
      Then
      \[
        h'(\theta)=\mathbb{E}(X(f)\mathrm{e}^{-X(\theta f + g)})=\exp\left(-\int_{E}(1-\mathrm{e}^{-\theta f(x) - g(x)} \mu(\d x))\right)\cdot \int_{E}f(x)\mathrm{e}^{-\theta f(x)-g(x)}\mu(\d x)
      \]
      Since they are all non-negative, the differential is valid.
      Let \(\theta = 0\), we get \(\mathbb{E}(X(f)\mathrm{e}^{-X(g)})=\mu(f \mathrm{e}^{-g})\mathbb{E}(\mathrm{e}^{-X(g)})\).
    \item Take \(h\) as above, easily to get \(h'' (\theta)=\mathbb{E}(X(f)^2)\mathrm{e}^{-X(g)}=\exp\left(-\int_{E}(1-\mathrm{e}^{-\theta f(x) - g(x)} \mu(\d x))\right)\cdot \left(\int_{E}f(x)\mathrm{e}^{-\theta f(x)-g(x)}\mu(\d x)\right)^2 + \exp\left(-\int_{E}(1-\mathrm{e}^{-\theta f(x) - g(x)} \mu(\d x))\right) \cdot \int_{E}f(x)^2 \mathrm{e}^{-\theta f(x) - g(x)}\mu(\d x)\).
      Let \(\theta =0\), then easily \(\mathbb{E}(X(f)^2 \mathrm{e}^{-X(g)})=(\mu(f^2 \mathrm{e}^{-g}+\mu(f \mathrm{e}^{-g})'2))\mathbb{E}(\mathrm{e}^{-X(g)})\).
  \end{enumerate}
\end{solution}

\end{document}
