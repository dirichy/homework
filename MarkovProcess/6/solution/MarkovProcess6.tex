%!Mode:: "TeX:UTF-8"
%!TEX TS-program = xelatex
\documentclass{ctexart}
\newif\ifpreface
%\prefacetrue
\input{../../../global/all}
\begin{document}
\large
\iffalse
  \setlength{\baselineskip}{1.2em}
  \ifpreface
    \input{../../../global/preface}
  \else
    \maketitle
  \fi
\fi
\newgeometry{left=2cm,right=2cm,top=2cm,bottom=2cm}
%from_here_to_type
\begin{problem}\label{pro:1}
  Assume \((\Omega,\mathcal{F},\mathbb{P})\) is a probability space, and \(C \in \mathcal{F}\) satisfy \(\mathbb{P}(C)>0\).
  Let \(\mathbb{P}_C:\mathcal{F} \to \mathbb{R},\mathbb{P}_C(X)=\frac{\mathbb{P}(C \cap X)}{\mathbb{P}(C)}\).
  Assume \(A,B \in \mathcal{F}\), and \(\mathbb{P}(B \cap C)>0\), prove that
  \(\mathbb{P}_C(A \mid B) = \mathbb{P}(A \mid B \cap C)\).
\end{problem}
\begin{solution}
  Easily \(\mathbb{P}_C(B)=\frac{\mathbb{P}(B \cap C)}{\mathbb{P}(C)}>0\), so \(\mathbb{P}_C(A \mid B)\) is well-defined.
  Easily to get that
  \[
    \mathbb{P}_C(A \mid B)=\frac{\mathbb{P}_C(A \cap B)}{\mathbb{P}_C(B)}=\frac{\frac{\mathbb{P}(A \cap B \cap C)}{\mathbb{P}(C)}}{\frac{\mathbb{P}(B \cap C)}{\mathbb{P}(C)}}=\frac{\mathbb{P}(A \cap B \cap C)}{\mathbb{P}(B \cap C)}=\mathbb{P}(A \mid B \cap C)
  \]
\end{solution}
\begin{problem}\label{pro:2}
  Assume that \((X_n:n \geq 0)\) is \(1\)-dimentional simple symetry random walk, prove that \((|X_n|:n \geq 0)\) is a Markov chain ranges in \(\mathbb{N}\).
\end{problem}
\begin{solution}
  Easy to know that \((X_n:n \geq 0)\) is a Markov chain in \(\mathbb{Z}\).
  Let \(\mathcal{F}_n:=\sigma(X_1,\cdots,X_n),\mathcal{G}_n:=\sigma(|X_1|,\cdots,|X_n|)\), then easily \(\mathcal{G}_n \subset \mathcal{F}_n\).
  Then we get that \(\mathbb{P}(|X_{n+1}|=i \mid \mathcal{F}_n)=\mathbb{P}(X_{n+1}=i \mid \mathcal{F}_n)+\mathbb{P}(X_{n+1}=-i \mid \mathcal{F}_n)=\mathbb{P}(X_{n+1}=i \mid X_n)+\mathbb{P}(X_{n+1}=-i \mid X_n)=\mathbb{P}(|X_{n+1}|=i \mid X_n)=\frac{1}{2}\mathbbm{1}(|X_n-i|=1)\).
  Noting \(i \geq 0\), we get that \(|X_n-i|=1 \iff ||X_n|-i|=1\), so \(\mathbb{P}(|X_{n+1}|=i \mid \mathcal{F}_n)\) is measureable about \(\sigma(|X_n|)\).
  Since \(\sigma(|X_n|)\subset \mathcal{G}_n \subset \mathcal{F}_n\), so we finally get that
  \(\mathbb{P}(|X_{n+1}|=i \mid \mathcal{G}_n)=\mathbb{P}(|X_{n+1}|=i \mid |X_n|)\).
  So \((|X_n|:n \geq 0)\) is a Markov chain.
\end{solution}
\begin{problem}\label{pro:3}
  Assume \((X_n:n \geq 0)\) is a Markov chain ranges in \(E\).
  Assume \(\phi:E \to F\) is injection.
  Prove that \((\phi(X_n):n \geq 0)\) is a Markov chain ranges in \(\phi(E)\).
\end{problem}
\begin{solution}
  Without loss of generality assume \(F=\phi(E)\), then \(\phi\) is bijection.
  Now let \(\mathcal{F}_n:=\sigma(X_1,\cdots,X_n)\).
  Since \(\phi\) is bijection we easily get that \(\sigma(X_n)=\sigma(\phi(X_n))\), so \(\mathcal{F}_n=\sigma(\phi(X_1),\cdots,\phi(X_n))\).
  Then \(\mathbb{P}(\phi(X_{n+1} =i \mid \mathcal{F}_n))=\mathbb{P}(X_{n+1}=\phi^{-1}(i) \mid \mathcal{F}_n)=\mathbb{P}(X_{n+1}=\phi^{-1}(i) \mid X_{n+1})=\mathbb{P}(\phi(X_{n+1})=i \mid \phi(X_n))\).
  So \((\phi(X_n):n \geq 0)\) is Markov chain.
\end{solution}
\begin{problem}\label{pro:4}
  Assume \((X_n:n \geq 0),(Y_n:n \geq 0)\) are two independent Markov chains on \(E,F\) respectively.
  Prove that \(((X_n,Y_n): n \geq 0)\) is Markov chain on \(E \times F\).
\end{problem}
\begin{solution}
  Let \(\mathcal{F}_n=\sigma(X_0,\cdots,X_n)\) and \(\mathcal{G}_n,=\sigma(Y_0,\cdots,Y_n)\),
  Let \(\mathcal{H}_n=\sigma((X_0,Y_0),\cdots,(X_n,Y_n))\).
  Then easily \(\mathcal{H}_n=\sigma(\mathcal{F}_n,\mathcal{G}_n)\).
  Easy to get that
  \[
    \begin{aligned}
      \mathbb{P}(X_{n+1} =i,Y_{n+1} =j \mid \mathcal{H}_n)
      =                                       & \mathbb{E}(\mathbb{P}(X_{n+1} =i,Y_{n+1} =j \mid \mathcal{H}_n,X_{n+1} )\mid \mathcal{H}_n)                            \\
      =                                       & \mathbb{E}(\mathbbm{1}_i(X_{n+1} )\mathbb{P}(Y_{n+1} =j \mid \mathcal{F}_n,\mathcal{G}_n,X_{n+1} ) \mid \mathcal{H}_n) \\
      (Y_{n+1} \perp \mathcal{F}_n,X_{n+1} )= & \mathbb{E}(\mathbbm{1}_i(X_{n+1} )\mathbb{P}(Y_{n+1} =j \mid Y_n) \mid \mathcal{H}_n)                                  \\
      (Y_n \in \mathcal{H}_n)=                & \mathbb{P}(Y_{n+1} =j \mid Y_n)\mathbb{P}(X_{n+1} =i \mid \mathcal{H}_n)                                               \\
      =                                       & \mathbb{P}(Y_{n+1} =j \mid Y_n)\mathbb{P}(X_{n+1} =i \mid X_n)                                                         \\
    \end{aligned}
  \]
  So \(\mathbb{P}(X_{n+1} =i,Y_{n+1}=j \mid \mathcal{H}_n) \in \sigma(X_n,Y_n) \subset \mathcal{H}_n\).
  So \(\mathbb{P}(X_{n+1}=i,Y_{n+1}=j \mid X_n,Y_n)=\mathbb{P}(X_{n+1}=i,Y_{n+1}=j \mid \mathcal{H}_n)\).
  So \(((X_n,Y_n):n \geq 0)\) is Markov chain.
\end{solution}
\begin{problem}\label{pro:5}
  Assume \((X_n:n \geq 0),(Y_n:n \geq 0)\) are two independent Markov chains on \(E,F\) respectively.
  Let \(\mathcal{H}_n:=\sigma((X_0,Y_0),\cdots,(X_n,Y_n))\).
  Prove that \((X_n:n \geq 0)\) is Markov chain over \((\mathcal{H}_n:n \geq 0)\).
\end{problem}
\begin{solution}
  Take \(\mathcal{F}_n,\mathcal{G}_n\) as above.
  Obviously \(X_n \in \mathcal{F}_n \subset \mathcal{H}_n\).
  Easily \(\mathbb{P}(X_{n+1}=i \mid \mathcal{H}_n)=\mathbb{P}(X_{n+1} =i \mid \mathcal{F}_n,\mathcal{G}_n)=\mathbb{P}(X_{n+1} =i \mid \mathcal{F}_n)=\mathbb{P}(X_{n+1} \mid X_n)\).
  So \((X_n:n \geq 0)\) is Markov chain over \((\mathcal{H}_n:n \geq 0)\).
\end{solution}
\begin{problem}\label{pro:6}
  Let \(\mu_0\) be a probability distribution on \(\mathbb{N}\).
  For \(n \geq 1\), let
  \[
    \mu_n(0)=\mu^{*2}_{n-1} (0)+\mu^{*2}_{n-1} (1),\mu_n(j)=\mu^{*2}_{n-1} (j+1),\forall j \geq 1
  \]
  Where \(\mu^{*2}=\mu*\mu\).
  Let \(F_n\) be distribution function of \(\mu_n\).
  Let \(F^{-1}_{n-1} (y):=\inf \{x \geq 0:y \leq F_{n-1} (x)\}\) for \(y \in [0,1]\).
  Assume \(X_0 \sim \mu_0\), and \((U_n:n \geq 0)\) are i.i.d r.v. with distribution \(U(0,1)\).
  Let \(X_{n+1} :=\max\{0,X_n +F^{-1}_n (U_n)-1\}\).
  Then \((X_n:n \geq 0)\) is Markov chain.
\end{problem}
\begin{solution}
  Let \(\mathcal{F}:=\sigma(X_0,\cdots,X_n)\).
  For \(i > 0\), we have
  \[
    \begin{aligned}
      \mathbb{P}(X_{n+1}=i \mid \mathcal{F}_n)
       & =\mathbb{P}(X_n+F^{-1}_n(U_n)-1=i \mid \mathcal{F}_n)                              \\
       & =\sum_{k \in \mathbb{Z}}\mathbb{P}(X_n=k,F^{-1}_n(U_n)=i+1-k \mid \mathcal{F}_n)   \\
       & =\sum_{k \in \mathbb{Z}}\mathbbm{1}_k(X_n)\mathbb{P}(F^{-1}_n(U_n)=i+1-k)          \\
       & =\sum_{k \in \mathbb{Z}}\mathbbm{1}_k(X_n)\mathbb{P}(F^{-1}_n(U_n)=i+1-k \mid X_n) \\
       & =\sum_{k \in \mathbb{Z}}\mathbb{P}(X_n=k,F^{-1}_n(U_n)=i+1-k \mid X_n)             \\
       & =\mathbb{P}(X_n+F^{-1}_n(U_n)-1=i \mid X_n) =\mathbb{P}(X_{n+1} =i \mid X_n)       \\
    \end{aligned}
  \]
  For \(i=0\), we have
  \[
    \begin{aligned}
      \mathbb{P}(X_{n+1}=0 \mid \mathcal{F}_n)
       & =\mathbb{P}(X_n+F^{-1}_n(U_n)-1\leq 0 \mid \mathcal{F}_n)                            \\
       & =\sum_{k \in \mathbb{Z}}\mathbb{P}(X_n=k,F^{-1}_n(U_n)\leq 1-k \mid \mathcal{F}_n)   \\
       & =\sum_{k \in \mathbb{Z}}\mathbbm{1}_k(X_n)\mathbb{P}(F^{-1}_n(U_n)\leq 1-k)          \\
       & =\sum_{k \in \mathbb{Z}}\mathbbm{1}_k(X_n)\mathbb{P}(F^{-1}_n(U_n)\leq 1-k \mid X_n) \\
       & =\sum_{k \in \mathbb{Z}}\mathbb{P}(X_n=k,F^{-1}_n(U_n)\leq 1-k \mid X_n)             \\
       & =\mathbb{P}(X_n+F^{-1}_n(U_n)-1\leq 0 \mid X_n) =\mathbb{P}(X_{n+1} = 0 \mid X_n)    \\
    \end{aligned}
  \]
  So \((X_n:n \geq 0)\) is Markov chain.
\end{solution}

\end{document}
